{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f02e95a-556d-4cfe-89b9-8bc2b5593549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/home/jamster/Repos/LLM-Experiments/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e8e3cb3-f648-4184-bc58-09cd63eefdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import decrypt\n",
    "\n",
    "hf_token = decrypt.decrypter()\n",
    "hf_token = hf_token.strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f6b0661-83f1-4bcc-9a80-f3798ca5d2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/jamster/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bc4f19a-15b9-4e8b-866a-aa6e82073686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f532f6a79dd4e00a617bdc94dea14ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576676533af444fa99ec2c9fa6a320f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54645147763244e8a1381825839759cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/632 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f1dae52664466daf1726e417c2f9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4aba8f43a3a416f9831f5e56136a619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/66.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46c5d6da4b9459ba71768e06c6ad2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/69.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642a420cc44941cfa5a9926faeaa7c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b33e2ff5614db5b4910438b2f9b1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/154 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207fcad6d5014fc89a552fbd56e8a2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Best_Platty_small.jpeg:   0%|          | 0.00/7.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f3adf4b11f749c7846ade3c9342a760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a4bdf78cca4bb0986148ee44d5a483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/698 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69fc54a2a5d478789d037083f418431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                              | 0/83 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard 1/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8886cedf4334b5e993c36c585dd3812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ae7e6904a14c649258a433056e2ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00015.bin:   0%|          | 0.00/9.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.embed_tokens.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▊                                                                                                                   | 2/83 [01:18<44:09, 32.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.0.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████▎                                                                                                                 | 3/83 [01:20<24:28, 18.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.1.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████▋                                                                                                                | 4/83 [01:21<15:20, 11.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.2.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███████                                                                                                               | 5/83 [01:22<10:19,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.3.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████████▌                                                                                                             | 6/83 [01:24<07:19,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.4.safetensors\n",
      "Loading shard 2/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ff41de2ccf405588c91e983bbf6126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08a7a6b8e2e44edb020f30c979091f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00015.bin:   0%|          | 0.00/9.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████████▉                                                                                                            | 7/83 [02:41<36:56, 29.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.5.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████▎                                                                                                          | 8/83 [02:43<25:24, 20.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.6.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████▊                                                                                                         | 9/83 [02:44<17:45, 14.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.7.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████                                                                                                       | 10/83 [02:45<12:38, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.8.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████████▌                                                                                                     | 11/83 [02:47<09:08,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.9.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████▉                                                                                                    | 12/83 [02:48<06:48,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.10.safetensors\n",
      "Loading shard 3/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03af75b5147e4392a717421f3899c86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7edccd335c4053893f845ed147c2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00003-of-00015.bin:   0%|          | 0.00/9.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████████▎                                                                                                  | 13/83 [04:09<33:11, 28.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.11.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████████▋                                                                                                 | 14/83 [04:10<23:19, 20.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.12.safetensors\n",
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.13.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████████████▌                                                                                              | 16/83 [04:13<11:54, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.14.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████▉                                                                                             | 17/83 [04:15<08:38,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.15.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████████▎                                                                                           | 18/83 [04:16<06:24,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.16.safetensors\n",
      "Loading shard 4/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f432b151ee10480189cbd642d51358c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370dce0111834628b39765ac1d5cfd0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00004-of-00015.bin:   0%|          | 0.00/9.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████████████▊                                                                                          | 19/83 [05:37<30:14, 28.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.17.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████████████▏                                                                                        | 20/83 [05:38<21:16, 20.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.18.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████████████▌                                                                                       | 21/83 [05:39<15:05, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.19.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████████████                                                                                      | 22/83 [05:41<10:49, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.20.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████████████▍                                                                                    | 23/83 [05:42<07:52,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.21.safetensors\n",
      "Loading shard 5/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0a6e6e7d4b41a4b64a97e9b26245b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9908d9b000ec462790bb7ccf06ab7dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00005-of-00015.bin:   0%|          | 0.00/9.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████████████▊                                                                                   | 24/83 [06:59<28:04, 28.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.22.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████▏                                                                                 | 25/83 [07:00<19:44, 20.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.23.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████████████████▋                                                                                | 26/83 [07:02<13:58, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.24.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████████████████                                                                               | 27/83 [07:03<10:01, 10.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.25.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████████████████▍                                                                             | 28/83 [07:05<07:16,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.26.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████████████████████▉                                                                            | 29/83 [07:06<05:25,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.27.safetensors\n",
      "Loading shard 6/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f45c658a9c41c4925ff7dcd5a73b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21abe13be13e40759d3aa0fdb5883b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00006-of-00015.bin:   0%|          | 0.00/9.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████████████████▎                                                                          | 30/83 [08:25<24:28, 27.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.28.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████████████████▋                                                                         | 31/83 [08:26<17:10, 19.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.29.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████████████████████                                                                        | 32/83 [08:27<12:08, 14.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.30.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████████▌                                                                      | 33/83 [08:29<08:40, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.31.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████████████████▉                                                                     | 34/83 [08:30<06:18,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.32.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████████████████████▎                                                                   | 35/83 [08:32<04:38,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.33.safetensors\n",
      "Loading shard 7/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fc837cdde84efab5032b039f9a7e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334653e709fd447ab262694255a9e987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00007-of-00015.bin:   0%|          | 0.00/9.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████████████████████▋                                                                  | 36/83 [09:49<21:26, 27.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.34.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████████████████████████████████████▏                                                                | 37/83 [09:51<15:03, 19.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.35.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████████████████████▌                                                               | 38/83 [09:52<10:38, 14.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.36.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████████████████████████████████████████▉                                                              | 39/83 [09:54<07:40, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.37.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████████████████████████████████████████▍                                                            | 40/83 [09:56<05:33,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.38.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████████████████████████▊                                                           | 41/83 [09:57<04:03,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.39.safetensors\n",
      "Loading shard 8/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85dd083e33494e0283d44f5575c830c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59ab660ab4f4e629124c2d60941d646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00008-of-00015.bin:   0%|          | 0.00/9.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████████████████████████████████████████████▏                                                         | 42/83 [11:14<18:32, 27.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.40.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████████████████████████▌                                                        | 43/83 [11:15<12:57, 19.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.41.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████████████████████████████████                                                       | 44/83 [11:17<09:07, 14.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.42.safetensors\n",
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.43.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████████████████████████████▊                                                    | 46/83 [11:20<04:43,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.44.safetensors\n",
      "Loading shard 9/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da609d155c648488d6321b744c2bc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3158c7347848b3a1043ec807fac5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00009-of-00015.bin:   0%|          | 0.00/9.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████████████████████████▎                                                  | 47/83 [12:36<17:01, 28.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.45.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████████████████████████████████████████████▋                                                 | 48/83 [12:38<11:51, 20.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.46.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████████████████████████████████████████████████████████████████████                                                | 49/83 [12:39<08:17, 14.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.47.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████████████████████████▍                                              | 50/83 [12:41<05:51, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.48.safetensors\n",
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.49.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████████████████████████████▎                                           | 52/83 [12:44<03:05,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.50.safetensors\n",
      "Loading shard 10/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0e627ad88e43449cbfb5b869a933a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e8109ca7cc4a47b081c9e589aca752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00010-of-00015.bin:   0%|          | 0.00/9.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████████████████████████████████████████████████████████████████████████▋                                          | 53/83 [14:02<13:49, 27.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.51.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████████████████████████████                                         | 54/83 [14:03<09:33, 19.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.52.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████████████████████████████▌                                       | 55/83 [14:05<06:39, 14.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.53.safetensors\n",
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.54.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████████████████████████████▎                                    | 57/83 [14:08<03:21,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.55.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████████████████████▊                                   | 58/83 [14:09<02:24,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.56.safetensors\n",
      "Loading shard 11/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da8494e602b4c4ea368f94fbd63cf3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf7702d49be401a8464c862a958d204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00011-of-00015.bin:   0%|          | 0.00/9.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████████████████████████████████▏                                 | 59/83 [15:27<11:00, 27.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.57.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|████████████████████████████████████████████████████████████████████████████████████▌                                | 60/83 [15:29<07:33, 19.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.58.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|█████████████████████████████████████████████████████████████████████████████████████▉                               | 61/83 [15:30<05:14, 14.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.59.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████████████████████████████████████████▍                             | 62/83 [15:32<03:38, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.60.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████████████████████████████████████▊                            | 63/83 [15:33<02:32,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.61.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████████████████████████████████████████████████████████████████▏                          | 64/83 [15:34<01:48,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.62.safetensors\n",
      "Loading shard 12/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1314f933a04643bbbd54f631d0d12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73bac4a8a0de44e3b3e9cf0fb25af40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00012-of-00015.bin:   0%|          | 0.00/9.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████▋                         | 65/83 [16:50<08:03, 26.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.63.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████                        | 66/83 [16:52<05:27, 19.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.64.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████████████████████████████████████████████████████████████████▍                      | 67/83 [16:53<03:42, 13.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.65.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████████████████████████████████████████████████▊                     | 68/83 [16:55<02:32, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.66.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 69/83 [16:56<01:45,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.67.safetensors\n",
      "Loading shard 13/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ee9e4ab4014205973ab0d63e44165e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0591e157df8747f6ad78a3af46b71aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00013-of-00015.bin:   0%|          | 0.00/9.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                  | 70/83 [18:15<06:16, 28.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.68.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████                 | 71/83 [18:16<04:08, 20.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.69.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍               | 72/83 [18:18<02:44, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.70.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉              | 73/83 [18:19<01:48, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.71.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 74/83 [18:21<01:12,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.72.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋           | 75/83 [18:22<00:48,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.73.safetensors\n",
      "Loading shard 14/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ed4bff699248c8b1e46e6f34aa6471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83775afceb624105a95fc4ba0820e9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00014-of-00015.bin:   0%|          | 0.00/9.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 76/83 [19:40<03:13, 27.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.74.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 77/83 [19:42<01:58, 19.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.75.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 78/83 [19:43<01:11, 14.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.76.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 79/83 [19:45<00:42, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.77.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 80/83 [19:46<00:23,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.78.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 81/83 [19:47<00:11,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.layers.79.safetensors\n",
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/model.norm.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 82/83 [19:48<00:04,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard 15/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606931d0d1404b86b1f4d52e6e845bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413a8199b4b4469b8b9e17975cfdda99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00015-of-00015.bin:   0%|          | 0.00/524M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [19:53<00:00, 14.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/31389b50953688e4e542be53e6d2ab04d5c34e87/splitted_model/lm_head.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AirLLMLlama2' object has no attribute '_supports_cache_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m input_text \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhat is the capital of United States?\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m input_tokens \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtokenizer(input_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39mMAX_LENGTH, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m generation_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tokens\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(generation_output\u001b[38;5;241m.\u001b[39msequences[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[0;32m~/llm_torch/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/llm_torch/lib/python3.11/site-packages/transformers/generation/utils.py:1777\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1774\u001b[0m         model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m cache_class(cache_config)\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;66;03m# Use DynamicCache() instance by default. This will avoid back and forth from legacy format that\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;66;03m# keeps copying the cache thus using much more memory\u001b[39;00m\n\u001b[0;32m-> 1777\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mcache_implementation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_supports_default_dynamic_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1778\u001b[0m     past \u001b[38;5;241m=\u001b[39m model_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/llm_torch/lib/python3.11/site-packages/transformers/generation/utils.py:1454\u001b[0m, in \u001b[0;36mGenerationMixin._supports_default_dynamic_cache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_supports_default_dynamic_cache\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1448\u001b[0m \u001b[38;5;124;03m    Return `True` if current model can use a `DynamicCache` instance when initializing the `past_key_values`.\u001b[39;00m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;124;03m    This is mostly the same as `_supports_cache_class` attribute, but add exception for `Jamba` model which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;124;03m    for `HybridMambaAttentionDynamicCache`).\u001b[39;00m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_supports_cache_class\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjamba\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mlower()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AirLLMLlama2' object has no attribute '_supports_cache_class'"
     ]
    }
   ],
   "source": [
    "from airllm import AutoModel, AirLLMLlama2, AirLLMMistral\n",
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=hf_token\n",
    "MAX_LENGTH = 128\n",
    "# could use hugging face model repo id:\n",
    "# model = AutoModel.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "model = AirLLMLlama2(\"garage-bAInd/Platypus2-70B-instruct\")\n",
    "\n",
    "# or use model's local path...\n",
    "#model = AutoModel.from_pretrained(\"/home/ubuntu/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/b585e74bcaae02e52665d9ac6d23f4d0dbc81a0f\")\n",
    "\n",
    "input_text = ['What is the capital of United States?']\n",
    "\n",
    "input_tokens = model.tokenizer(input_text, return_tensors=\"pt\", return_attention_mask=False, truncation=True, max_length=MAX_LENGTH, padding=False)\n",
    "           \n",
    "generation_output = model.generate(input_tokens['input_ids'].cuda(), max_new_tokens=20, use_cache=True, return_dict_in_generate=True)\n",
    "\n",
    "output = model.tokenizer.decode(generation_output.sequences[0])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "938df231-1803-45a8-ac68-31b2c1e2ca03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e40217c4514d7bb77224078f722090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6d3501095d4670af0c2d304876edec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c353319c9eb4b4ea81dcc2459e17dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/22.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eae63d4186d43b7a6539fbd24f9c9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f362eb3528da45a5807345b0efbd52bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE.txt:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2646d23a474db5a2d63d3c29bafc83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f0f357d4ec43ca964b141074d80095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e626b35e06d04b2f808dce80e0af1f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ba4951804e4495ba5956eae5762613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cba38992a84d4fa04f721939d745dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "USE_POLICY.md:   0%|          | 0.00/4.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b874cff1da5450ca630abf56df043ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63403541911d4795910cf126b3a00800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a09adde0264b1ab911b0d24bbecbb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                              | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard 1/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6317218e0b144efba580f153b36e40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d68e3d49ed54e10826dac72c6abb332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▎                                                                                                                  | 1/35 [01:14<42:26, 74.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.embed_tokens.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████▋                                                                                                               | 2/35 [01:15<17:06, 31.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.0.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████████                                                                                                            | 3/35 [01:15<09:06, 17.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.1.safetensors\n",
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.2.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████▊                                                                                                     | 5/35 [01:16<03:26,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.3.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████████▏                                                                                                 | 6/35 [01:17<02:15,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.4.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████▌                                                                                              | 7/35 [01:17<01:32,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.5.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████████████▉                                                                                           | 8/35 [01:17<01:04,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.6.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████████████▎                                                                                       | 9/35 [01:18<00:46,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.7.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████████████▍                                                                                   | 10/35 [01:18<00:34,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.8.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████████████████▊                                                                                | 11/35 [01:19<00:26,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.9.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████████████████                                                                             | 12/35 [01:19<00:20,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.10.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████████████████▍                                                                         | 13/35 [01:20<00:16,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.11.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████████▊                                                                      | 14/35 [01:20<00:14,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.12.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████████████████████▏                                                                  | 15/35 [01:21<00:11,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.13.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████████████████████▍                                                               | 16/35 [01:21<00:10,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.14.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████████████████████████████████████████▊                                                            | 17/35 [01:22<00:09,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.15.safetensors\n",
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.16.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████████████████████████████▌                                                     | 19/35 [01:23<00:08,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.17.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████████████████████████▊                                                  | 20/35 [01:23<00:07,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.18.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████████████████████████▏                                              | 21/35 [01:24<00:06,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.19.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████████████████████████████▌                                           | 22/35 [01:24<00:05,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.20.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████████████████████████████▉                                        | 23/35 [01:24<00:05,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.21.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████████████████████████████▏                                    | 24/35 [01:25<00:04,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.22.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████████████████████████████████▌                                 | 25/35 [01:25<00:03,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.23.safetensors\n",
      "Loading shard 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1735cd82fe174a07b0f7bd33885d30ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15bb858b3704dd98b30473fabc4fe13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████████████████████████████████████████████████████████████████████▉                              | 26/35 [01:51<01:13,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.24.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████████████████████████████████████████████████████████████████▎                          | 27/35 [01:52<00:46,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.25.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████▌                       | 28/35 [01:52<00:29,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.26.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████████▉                    | 29/35 [01:52<00:18,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.27.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████▎                | 30/35 [01:53<00:11,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.28.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 31/35 [01:53<00:06,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.29.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉          | 32/35 [01:53<00:03,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.30.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▎      | 33/35 [01:54<00:01,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.layers.31.safetensors\n",
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/model.norm.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [01:54<00:00,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: /home/jamster/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/splitted_model/lm_head.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AirLLMLlama2' object has no attribute '_supports_cache_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 23\u001b[0m\n\u001b[1;32m     10\u001b[0m input_text \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m#'What is the capital of China?',\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI like\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m     ]\n\u001b[1;32m     15\u001b[0m input_tokens \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtokenizer(input_text,\n\u001b[1;32m     16\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m#padding=True\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     )\n\u001b[0;32m---> 23\u001b[0m generation_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tokens\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(generation_output\u001b[38;5;241m.\u001b[39msequences[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/llm_torch/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/llm_torch/lib/python3.11/site-packages/transformers/generation/utils.py:1777\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1774\u001b[0m         model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m cache_class(cache_config)\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;66;03m# Use DynamicCache() instance by default. This will avoid back and forth from legacy format that\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;66;03m# keeps copying the cache thus using much more memory\u001b[39;00m\n\u001b[0;32m-> 1777\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mcache_implementation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_supports_default_dynamic_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1778\u001b[0m     past \u001b[38;5;241m=\u001b[39m model_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/llm_torch/lib/python3.11/site-packages/transformers/generation/utils.py:1454\u001b[0m, in \u001b[0;36mGenerationMixin._supports_default_dynamic_cache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_supports_default_dynamic_cache\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1448\u001b[0m \u001b[38;5;124;03m    Return `True` if current model can use a `DynamicCache` instance when initializing the `past_key_values`.\u001b[39;00m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;124;03m    This is mostly the same as `_supports_cache_class` attribute, but add exception for `Jamba` model which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;124;03m    for `HybridMambaAttentionDynamicCache`).\u001b[39;00m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_supports_cache_class\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjamba\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mlower()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AirLLMLlama2' object has no attribute '_supports_cache_class'"
     ]
    }
   ],
   "source": [
    "from airllm import AutoModel\n",
    "\n",
    "MAX_LENGTH = 128\n",
    "# could use hugging face model repo id:\n",
    "model = AutoModel.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", profiling_mode=True)\n",
    "\n",
    "# or use model's local path...\n",
    "#model = AirLLMLlama2(\"/home/ubuntu/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/b585e74bcaae02e52665d9ac6d23f4d0dbc81a0f\")\n",
    "\n",
    "input_text = [\n",
    "        #'What is the capital of China?',\n",
    "        'I like',\n",
    "    ]\n",
    "\n",
    "input_tokens = model.tokenizer(input_text,\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=False,\n",
    "    truncation=True,\n",
    "    max_length=MAX_LENGTH,\n",
    "    #padding=True\n",
    "    )\n",
    "\n",
    "generation_output = model.generate(\n",
    "    input_tokens['input_ids'].cuda(),\n",
    "    max_new_tokens=3,\n",
    "    use_cache=True,\n",
    "    return_dict_in_generate=True)\n",
    "\n",
    "model.tokenizer.decode(generation_output.sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122a15a7-b9bf-42c9-a490-0d702c88a152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_torch",
   "language": "python",
   "name": "llm_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
